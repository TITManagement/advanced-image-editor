"""
å®Ÿé¨“åŸºç›¤ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ - Experiment Framework Base

æ©Ÿæ¢°å­¦ç¿’å®Ÿé¨“ã®å‰å‡¦ç†ã€å­¦ç¿’ã€è©•ä¾¡ã‚’ç®¡ç†ã™ã‚‹åŸºæœ¬ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
æ—¢å­˜ã®ç”»åƒå‡¦ç†ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã¨é€£æºå¯èƒ½
"""

import os
import sys
import json
import time
import pickle
from abc import ABC, abstractmethod
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
import traceback

import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error, accuracy_score
from sklearn.model_selection import train_test_split

# æ—¢å­˜ã®ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆ©ç”¨
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'src'))
try:
    from core.plugin_base import PluginManager, ImageProcessorPlugin
    from plugins.basic.basic_plugin import BasicAdjustmentPlugin
    from plugins.density.density_plugin import DensityAdjustmentPlugin
    from plugins.filters.filters_plugin import FilterPlugin
    from plugins.advanced.advanced_plugin import AdvancedProcessingPlugin
    PLUGINS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¤ãƒ³ãƒãƒ¼ãƒˆè­¦å‘Š: {e}")
    PLUGINS_AVAILABLE = False

# ã‚¹ã‚­ãƒ¼ãƒ
from contracts.schemas.experiment import (
    ExperimentConfig, ExperimentRun, ExperimentStatus,
    DatasetMetadata, DataSample, EvaluationMetrics
)
from contracts.schemas.image_processing import ProcessingStatus


class ExperimentFramework:
    """å®Ÿé¨“ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, experiment_config: ExperimentConfig):
        self.config = experiment_config
        self.experiment_dir = Path(experiment_config.output_dir)
        self.experiment_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ­ã‚°è¨­å®š
        self.log_file = self.experiment_dir / "experiment.log"
        
        # æ—¢å­˜ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
        self.plugin_manager = None
        if PLUGINS_AVAILABLE:
            self._initialize_plugins()
    
    def _initialize_plugins(self):
        """æ—¢å­˜ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–"""
        try:
            self.plugin_manager = PluginManager()
            
            # åŸºæœ¬ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ç™»éŒ²
            plugins = [
                BasicAdjustmentPlugin(),
                DensityAdjustmentPlugin(),
                FilterPlugin(),
                AdvancedProcessingPlugin()
            ]
            
            for plugin in plugins:
                self.plugin_manager.register_plugin(plugin)
            
            self.log(f"âœ… {len(plugins)}å€‹ã®ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ç™»éŒ²ã—ã¾ã—ãŸ")
            
        except Exception as e:
            self.log(f"âš ï¸ ãƒ—ãƒ©ã‚°ã‚¤ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.plugin_manager = None
    
    def log(self, message: str, level: str = "INFO"):
        """ãƒ­ã‚°å‡ºåŠ›"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] [{level}] {message}"
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
        print(log_entry)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        try:
            with open(self.log_file, "a", encoding="utf-8") as f:
                f.write(log_entry + "\n")
        except Exception as e:
            print(f"âš ï¸ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def save_experiment_metadata(self, run_id: str, metadata: Dict[str, Any]):
        """å®Ÿé¨“ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        metadata_file = self.experiment_dir / f"metadata_{run_id}.json"
        
        try:
            with open(metadata_file, "w", encoding="utf-8") as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
            
            self.log(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {metadata_file}")
            
        except Exception as e:
            self.log(f"âŒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}", "ERROR")


class ImageProcessingExperiment(ExperimentFramework):
    """ç”»åƒå‡¦ç†å®Ÿé¨“ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, experiment_config: ExperimentConfig):
        super().__init__(experiment_config)
        self.training_data = []
        self.validation_data = []
        self.test_data = []
    
    def load_dataset(self, dataset_metadata: DatasetMetadata) -> List[DataSample]:
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿"""
        self.log(f"ğŸ“¦ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿é–‹å§‹: {dataset_metadata.name}")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’èª­ã¿è¾¼ã¿
            data_path = Path(dataset_metadata.data_path)
            samples = []
            
            if data_path.exists():
                # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
                image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
                image_files = []
                
                for ext in image_extensions:
                    image_files.extend(data_path.glob(f"**/*{ext}"))
                    image_files.extend(data_path.glob(f"**/*{ext.upper()}"))
                
                for i, image_file in enumerate(image_files):
                    sample = DataSample(
                        sample_id=f"{dataset_metadata.dataset_id}_sample_{i:04d}",
                        dataset_id=dataset_metadata.dataset_id,
                        input_path=str(image_file),
                        metadata={
                            "file_size": image_file.stat().st_size,
                            "created_at": datetime.now().isoformat()
                        }
                    )
                    samples.append(sample)
                
                self.log(f"âœ… {len(samples)}å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            else:
                self.log(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_path}", "WARNING")
            
            return samples
            
        except Exception as e:
            self.log(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            return []
    
    def preprocess_data(self, samples: List[DataSample]) -> List[Dict[str, Any]]:
        """ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†"""
        self.log("ğŸ”„ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†é–‹å§‹")
        
        processed_data = []
        
        for sample in samples:
            try:
                # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—
                input_path = Path(sample.input_path)
                
                if input_path.exists():
                    processed_sample = {
                        "sample_id": sample.sample_id,
                        "input_path": str(input_path),
                        "metadata": sample.metadata,
                        "processed_at": datetime.now().isoformat()
                    }
                    processed_data.append(processed_sample)
                
            except Exception as e:
                self.log(f"âš ï¸ ã‚µãƒ³ãƒ—ãƒ«å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {sample.sample_id}, {e}", "WARNING")
                continue
        
        self.log(f"âœ… {len(processed_data)}å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’å‰å‡¦ç†ã—ã¾ã—ãŸ")
        return processed_data
    
    def apply_processing_pipeline(self, sample_data: Dict[str, Any], 
                                plugin_params: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """æ—¢å­˜ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ãŸå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é©ç”¨"""
        if not self.plugin_manager:
            self.log("âš ï¸ ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“", "WARNING")
            return sample_data
        
        try:
            from PIL import Image
            
            # å…¥åŠ›ç”»åƒã‚’èª­ã¿è¾¼ã¿
            input_image = Image.open(sample_data["input_path"])
            result_image = input_image.copy()
            
            processing_results = []
            
            # å„ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’é †æ¬¡é©ç”¨
            for plugin in self.plugin_manager.get_enabled_plugins():
                plugin_name = plugin.name
                
                if plugin_name in plugin_params:
                    params = plugin_params[plugin_name]
                    
                    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
                    for param_name, value in params.items():
                        if param_name in plugin._sliders:
                            plugin._sliders[param_name].set(value)
                    
                    # å‡¦ç†å®Ÿè¡Œ
                    start_time = time.time()
                    result_image = plugin.process_image(result_image, **params)
                    processing_time = time.time() - start_time
                    
                    processing_results.append({
                        "plugin": plugin_name,
                        "parameters": params,
                        "processing_time": processing_time,
                        "status": "completed"
                    })
                    
                    self.log(f"ğŸ”§ {plugin_name} å‡¦ç†å®Œäº† ({processing_time:.3f}s)")
            
            # çµæœç”»åƒã‚’ä¿å­˜
            output_path = self.experiment_dir / "processed" / f"{sample_data['sample_id']}_processed.jpg"
            output_path.parent.mkdir(exist_ok=True)
            result_image.save(output_path)
            
            # çµæœãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
            result_data = sample_data.copy()
            result_data.update({
                "output_path": str(output_path),
                "processing_results": processing_results,
                "total_processing_time": sum(r["processing_time"] for r in processing_results)
            })
            
            return result_data
            
        except Exception as e:
            self.log(f"âŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            self.log(traceback.format_exc(), "ERROR")
            return sample_data
    
    def run_experiment(self, run_id: Optional[str] = None) -> ExperimentRun:
        """å®Ÿé¨“å®Ÿè¡Œ"""
        if not run_id:
            run_id = f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        self.log(f"ğŸš€ å®Ÿé¨“å®Ÿè¡Œé–‹å§‹: {run_id}")
        start_time = datetime.now()
        
        try:
            # å®Ÿé¨“å®Ÿè¡Œè¨˜éŒ²ã‚’ä½œæˆ
            experiment_run = ExperimentRun(
                run_id=run_id,
                experiment_id=self.config.experiment_id,
                config=self.config,
                status=ExperimentStatus.RUNNING,
                start_time=start_time
            )
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
            sample_dataset = DatasetMetadata(
                dataset_id=self.config.training_dataset_id,
                name="Training Dataset",
                dataset_type="training",
                total_samples=0,
                data_path="SampleImage/"  # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            )
            
            samples = self.load_dataset(sample_dataset)
            processed_data = self.preprocess_data(samples)
            
            # ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆä¾‹ï¼‰
            plugin_params = {
                "basic_adjustment": {
                    "brightness": self.config.hyperparameters.get("brightness", 10.0),
                    "contrast": self.config.hyperparameters.get("contrast", 5.0),
                    "saturation": self.config.hyperparameters.get("saturation", 0.0)
                },
                "density_adjustment": {
                    "gamma": self.config.hyperparameters.get("gamma", 1.2),
                    "shadow": self.config.hyperparameters.get("shadow", -5.0),
                    "highlight": self.config.hyperparameters.get("highlight", 5.0)
                }
            }
            
            # å„ã‚µãƒ³ãƒ—ãƒ«ã«å‡¦ç†ã‚’é©ç”¨
            results = []
            for sample_data in processed_data:
                result = self.apply_processing_pipeline(sample_data, plugin_params)
                results.append(result)
            
            # è©•ä¾¡å®Ÿè¡Œ
            evaluation_metrics = self.evaluate_results(results)
            
            # å®Ÿé¨“çµ‚äº†
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            experiment_run.status = ExperimentStatus.COMPLETED
            experiment_run.end_time = end_time
            experiment_run.duration_seconds = duration
            experiment_run.final_evaluation = evaluation_metrics
            experiment_run.artifacts_path = str(self.experiment_dir)
            experiment_run.log_path = str(self.log_file)
            
            self.log(f"ğŸ‰ å®Ÿé¨“å®Œäº†: {run_id} (å®Ÿè¡Œæ™‚é–“: {duration:.2f}ç§’)")
            
            # çµæœä¿å­˜
            self.save_experiment_metadata(run_id, {
                "run_id": run_id,
                "config": self.config.dict(),
                "results": results,
                "evaluation": evaluation_metrics.dict() if evaluation_metrics else None,
                "duration_seconds": duration
            })
            
            return experiment_run
            
        except Exception as e:
            self.log(f"âŒ å®Ÿé¨“å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            self.log(traceback.format_exc(), "ERROR")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®å®Ÿé¨“è¨˜éŒ²æ›´æ–°
            experiment_run.status = ExperimentStatus.FAILED
            experiment_run.error_message = str(e)
            experiment_run.error_traceback = traceback.format_exc()
            
            return experiment_run
    
    def evaluate_results(self, results: List[Dict[str, Any]]) -> Optional[EvaluationMetrics]:
        """çµæœè©•ä¾¡"""
        self.log("ğŸ“Š çµæœè©•ä¾¡é–‹å§‹")
        
        try:
            # åŸºæœ¬çš„ãªå‡¦ç†æ€§èƒ½æŒ‡æ¨™ã‚’è¨ˆç®—
            processing_times = [r.get("total_processing_time", 0) for r in results]
            success_count = len([r for r in results if "output_path" in r])
            
            avg_processing_time = np.mean(processing_times) if processing_times else 0
            success_rate = success_count / len(results) if results else 0
            
            # ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡æŒ‡æ¨™
            custom_metrics = {
                "samples_processed": len(results),
                "success_count": success_count,
                "success_rate": success_rate,
                "avg_processing_time": avg_processing_time,
                "total_processing_time": sum(processing_times)
            }
            
            evaluation_metrics = EvaluationMetrics(
                accuracy=success_rate,
                custom_metrics=custom_metrics
            )
            
            self.log(f"âœ… è©•ä¾¡å®Œäº†: æˆåŠŸç‡ {success_rate:.2%}, å¹³å‡å‡¦ç†æ™‚é–“ {avg_processing_time:.3f}ç§’")
            
            return evaluation_metrics
            
        except Exception as e:
            self.log(f"âŒ è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            return None


def create_sample_experiment() -> ExperimentConfig:
    """ã‚µãƒ³ãƒ—ãƒ«å®Ÿé¨“è¨­å®šã‚’ä½œæˆ"""
    experiment_config = ExperimentConfig(
        experiment_id="sample_exp_001",
        name="ã‚µãƒ³ãƒ—ãƒ«ç”»åƒå‡¦ç†å®Ÿé¨“",
        description="æ—¢å­˜ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ãŸåŸºæœ¬çš„ãªç”»åƒå‡¦ç†å®Ÿé¨“",
        model_type="enhancement",
        training_dataset_id="sample_dataset",
        hyperparameters={
            "brightness": 10.0,
            "contrast": 5.0,
            "saturation": 0.0,
            "gamma": 1.2,
            "shadow": -5.0,
            "highlight": 5.0
        },
        epochs=1,  # ç”»åƒå‡¦ç†ã®å ´åˆã¯1å›ã®å‡¦ç†
        output_dir="data/experiments/sample_exp_001"
    )
    
    return experiment_config


if __name__ == "__main__":
    """ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œæ™‚ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª å®Ÿé¨“ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ã‚µãƒ³ãƒ—ãƒ«å®Ÿé¨“è¨­å®šã‚’ä½œæˆ
    config = create_sample_experiment()
    
    # å®Ÿé¨“ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
    experiment = ImageProcessingExperiment(config)
    
    # å®Ÿé¨“å®Ÿè¡Œ
    result = experiment.run_experiment()
    
    print(f"\nğŸ¯ å®Ÿé¨“çµæœ:")
    print(f"  å®Ÿé¨“ID: {result.experiment_id}")
    print(f"  å®Ÿè¡ŒID: {result.run_id}")
    print(f"  ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {result.status}")
    print(f"  å®Ÿè¡Œæ™‚é–“: {result.duration_seconds:.2f}ç§’")
    
    if result.final_evaluation:
        print(f"  è©•ä¾¡çµæœ: {result.final_evaluation.custom_metrics}")
    
    print("\nğŸ å®Ÿé¨“ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†")