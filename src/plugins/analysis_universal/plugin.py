#!/usr/bin/env python3
"""
Universal Analysis Plugin - UniversalPluginBaseä½¿ç”¨

KISSåŸå‰‡ã«å¾“ã£ãŸç°¡æ½”ãªå®Ÿè£…
"""

import cv2
import numpy as np
from PIL import Image
from typing import Dict, Any, Optional

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.universal_plugin_base import UniversalPluginBase


class UniversalAnalysisPlugin(UniversalPluginBase):
    """Universal Analysis Plugin - ç”»åƒè§£ææ©Ÿèƒ½ã‚’æä¾›"""
    
    def __init__(self):
        super().__init__("analysis", "1.0.0")
    
    def apply_filter(self, image: Image.Image, filter_type: str, **kwargs) -> Image.Image:
        """è§£æå‡¦ç†ã®ãƒ¡ã‚¤ãƒ³å®Ÿè£…"""
        if not image:
            return image
            
        try:
            if filter_type == "histogram":
                return self._apply_histogram_analysis(image)
            elif filter_type == "rgb_histogram":
                return self._apply_rgb_histogram_analysis(image)
            elif filter_type == "sift":
                return self._apply_feature_detection(image, "sift")
            elif filter_type == "orb":
                return self._apply_feature_detection(image, "orb")
            elif filter_type == "dct":
                return self._apply_frequency_analysis(image, "dct")
            elif filter_type == "fft":
                return self._apply_frequency_analysis(image, "fft")
            elif filter_type == "noise":
                return self._apply_noise_analysis(image)
            elif filter_type == "blur":
                return self._apply_blur_analysis(image)
            else:
                return image
                
        except Exception as e:
            print(f"âŒ è§£æå‡¦ç†ã‚¨ãƒ©ãƒ¼ ({filter_type}): {e}")
            return image
    
    def process_image(self, image: Image.Image) -> Image.Image:
        """åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚ˆã‚‹ç”»åƒå‡¦ç†ï¼ˆè§£æã¯å€‹åˆ¥ãƒœã‚¿ãƒ³ã®ã¿ï¼‰"""
        return image
    
    def _apply_histogram_analysis(self, image: Image.Image) -> Image.Image:
        """ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è§£æï¼ˆOpenCVå®Œå…¨ç‰ˆï¼‰"""
        try:
            print("ğŸ“Š ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è§£æé–‹å§‹")
            img_array = np.array(image)
            
            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
            if img_array.ndim == 3:
                img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            else:
                img_gray = img_array
            
            # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è¨ˆç®—
            hist = cv2.calcHist([img_gray], [0], None, [256], [0,256])
            
            # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ç”»åƒç”Ÿæˆï¼ˆå…ƒã®å®Ÿè£…ã¨åŒã˜ï¼‰
            hist_img = np.full((100, 256, 3), 255, np.uint8)
            cv2.normalize(hist, hist, 0, 100, cv2.NORM_MINMAX)
            for x, y in enumerate(hist):
                cv2.line(hist_img, (x, 100), (x, 100-int(y)), (0,0,0), 1)
            
            print("âœ… ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è§£æå®Œäº†")
            return Image.fromarray(hist_img)
        except Exception as e:
            print(f"âŒ ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return image
    
    def _apply_rgb_histogram_analysis(self, image: Image.Image) -> Image.Image:
        """RGBãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è§£æï¼ˆOpenCVå®Œå…¨ç‰ˆï¼‰"""
        try:
            print("ğŸŒˆ RGBãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è§£æé–‹å§‹")
            img_array = np.array(image)
            
            # RGBåˆ¥ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ç”»åƒç”Ÿæˆï¼ˆå…ƒã®å®Ÿè£…ã¨åŒã˜ï¼‰
            hist_img = np.full((100, 256, 3), 255, np.uint8)
            colors = [(255,0,0), (0,255,0), (0,0,255)]  # BGRé †
            
            for i, col in enumerate(colors):
                hist = cv2.calcHist([img_array], [i], None, [256], [0,256])
                cv2.normalize(hist, hist, 0, 100, cv2.NORM_MINMAX)
                for x, y in enumerate(hist):
                    cv2.line(hist_img, (x, 100), (x, 100-int(y)), col, 1)
            
            print("âœ… RGBãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è§£æå®Œäº†")
            return Image.fromarray(hist_img)
        except Exception as e:
            print(f"âŒ RGBãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return image
    
    def _apply_frequency_analysis(self, image: Image.Image, analysis_type: str) -> Image.Image:
        """å‘¨æ³¢æ•°è§£æï¼ˆOpenCVå®Œå…¨ç‰ˆï¼‰"""
        try:
            print(f"ğŸ“ˆ {analysis_type.upper()}è§£æé–‹å§‹")
            img_gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
            
            if analysis_type == 'dct':
                # DCTï¼ˆå…ƒã®å®Ÿè£…ã¨åŒã˜ï¼‰
                img_float = np.float32(img_gray) / 255.0
                original_shape = img_float.shape
                
                # å¥‡æ•°ã‚µã‚¤ã‚ºã®å ´åˆã€å¶æ•°ã‚µã‚¤ã‚ºã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
                h, w = img_float.shape  # type: ignore
                new_h = h if h % 2 == 0 else h + 1
                new_w = w if w % 2 == 0 else w + 1
                
                if new_h != h or new_w != w:
                    padded_img = np.zeros((new_h, new_w), dtype=np.float32)  # type: ignore
                    padded_img[:h, :w] = img_float  # type: ignore
                    img_float = padded_img
                
                dct = cv2.dct(img_float)  # type: ignore
                dct_log = np.log(np.abs(dct) + 1e-5)  # type: ignore
                dct_norm = cv2.normalize(dct_log, None, 0, 255, cv2.NORM_MINMAX)  # type: ignore
                dct_img = np.uint8(dct_norm)  # type: ignore
                
                # å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™
                if new_h != original_shape[0] or new_w != original_shape[1]:  # type: ignore
                    dct_img = dct_img[:original_shape[0], :original_shape[1]]  # type: ignore
                
                result = cv2.cvtColor(dct_img, cv2.COLOR_GRAY2RGB)  # type: ignore
                print("âœ… DCTè§£æå®Œäº†")
                return Image.fromarray(result)
                
            elif analysis_type == 'fft':
                # FFTï¼ˆå…ƒã®å®Ÿè£…ã¨åŒã˜ï¼‰
                f = np.fft.fft2(img_gray)  # type: ignore
                fshift = np.fft.fftshift(f)  # type: ignore
                magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-5)  # type: ignore
                mag_norm = cv2.normalize(magnitude_spectrum, None, 0, 255, cv2.NORM_MINMAX)  # type: ignore
                mag_img = np.uint8(mag_norm)  # type: ignore
                result = cv2.cvtColor(mag_img, cv2.COLOR_GRAY2RGB)  # type: ignore
                print("âœ… FFTè§£æå®Œäº†")
                return Image.fromarray(result)
                
        except Exception as e:
            print(f"âŒ {analysis_type.upper()}è§£æã‚¨ãƒ©ãƒ¼: {e}")
        return image
    
    def _apply_noise_analysis(self, image: Image.Image) -> Image.Image:
        """ãƒã‚¤ã‚ºè§£æï¼ˆOpenCVå®Œå…¨ç‰ˆï¼‰"""
        try:
            print("ğŸ” ãƒã‚¤ã‚ºè§£æé–‹å§‹")
            gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
            
            # ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«è¨ˆç®—ï¼ˆå…ƒã®å®Ÿè£…ã¨åŒã˜ï¼‰
            noise_level = np.std(gray.astype(np.float32))
            status = "é«˜" if noise_level > 50 else "ä¸­" if noise_level > 25 else "ä½"
            color = (255,0,0) if noise_level > 50 else (255,255,0) if noise_level > 25 else (0,255,0)
            
            # çµæœç”»åƒã«æƒ…å ±æç”»
            result = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            cv2.putText(result, f"Noise: {status} ({noise_level:.1f})", (10,30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
            
            print("âœ… ãƒã‚¤ã‚ºè§£æå®Œäº†")
            return Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))
        except Exception as e:
            print(f"âŒ ãƒã‚¤ã‚ºè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return image
    
    def _apply_blur_analysis(self, image: Image.Image) -> Image.Image:
        """ãƒ–ãƒ©ãƒ¼è§£æï¼ˆOpenCVå®Œå…¨ç‰ˆï¼‰"""
        try:
            print("ğŸ’« ãƒ–ãƒ©ãƒ¼è§£æé–‹å§‹")
            gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
            
            # ãƒ–ãƒ©ãƒ¼åº¦è¨ˆç®—ï¼ˆå…ƒã®å®Ÿè£…ã¨åŒã˜ï¼‰
            blur_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            status = "å¼·" if blur_var < 50 else "ä¸­" if blur_var < 150 else "å¼±"
            color = (255,0,0) if blur_var < 50 else (255,255,0) if blur_var < 150 else (0,255,0)
            
            # çµæœç”»åƒã«æƒ…å ±æç”»
            result = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            cv2.putText(result, f"Blur: {status} ({blur_var:.1f})", (10,30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
            
            print("âœ… ãƒ–ãƒ©ãƒ¼è§£æå®Œäº†")
            return Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))
        except Exception as e:
            print(f"âŒ ãƒ–ãƒ©ãƒ¼è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return image
    
    def _apply_feature_detection(self, image: Image.Image, feature_type: str) -> Image.Image:
        """ç‰¹å¾´ç‚¹æ¤œå‡ºï¼ˆOpenCVå®Œå…¨ç‰ˆï¼‰"""
        try:
            print(f"ğŸ¯ {feature_type.upper()}ç‰¹å¾´ç‚¹æ¤œå‡ºé–‹å§‹")
            gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
            keypoints = []
            
            # ç‰¹å¾´ç‚¹æ¤œå‡ºï¼ˆå…ƒã®å®Ÿè£…ã¨åŒã˜ï¼‰
            if feature_type == "sift" and hasattr(cv2, "SIFT_create"):
                sift = cv2.SIFT_create()  # type: ignore
                keypoints = sift.detect(gray, None)  # type: ignore
            elif feature_type == "orb" and hasattr(cv2, "ORB_create"):
                orb = cv2.ORB_create()  # type: ignore
                keypoints = orb.detect(gray, None)  # type: ignore
            
            if keypoints:
                result = np.array(image)
                color = (0,255,0) if feature_type == "sift" else (255,0,0)
                
                # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»
                for kp in keypoints:
                    x, y = int(kp.pt[0]), int(kp.pt[1])
                    radius = int(max(10, kp.size / 2))
                    cv2.circle(result, (x, y), radius, color, 2)
                
                print(f"âœ… {feature_type.upper()}ç‰¹å¾´ç‚¹æ¤œå‡ºå®Œäº†: {len(keypoints)}å€‹")
                return Image.fromarray(result)
            else:
                print(f"âš ï¸ {feature_type.upper()}ç‰¹å¾´ç‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
        except Exception as e:
            print(f"âŒ {feature_type.upper()}ç‰¹å¾´ç‚¹æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return image