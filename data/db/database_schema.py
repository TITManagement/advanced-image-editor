"""
DuckDB ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã¨ã‚¹ã‚­ãƒ¼ãƒè¨­å®š

ç”»åƒå‡¦ç†ãƒ‡ãƒ¼ã‚¿ã€å®Ÿé¨“å±¥æ­´ã€ãƒ¢ãƒ‡ãƒ«ç®¡ç†ç”¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å®šç¾©
PostgreSQLç§»è¡Œã‚’è¦‹æ®ãˆãŸã‚¹ã‚­ãƒ¼ãƒè¨­è¨ˆ
"""

import duckdb
from pathlib import Path
from datetime import datetime
from typing import Optional


class DatabaseManager:
    """DuckDBãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
    
    def __init__(self, db_path: str = "data/db/advanced_image_editor.duckdb"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.connection = None
    
    def connect(self) -> duckdb.DuckDBPyConnection:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š"""
        if self.connection is None:
            self.connection = duckdb.connect(str(self.db_path))
        return self.connection
    
    def close(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’é–‰ã˜ã‚‹"""
        if self.connection:
            self.connection.close()
            self.connection = None
    
    def initialize_schema(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã‚’åˆæœŸåŒ–"""
        conn = self.connect()
        
        # æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‰Šé™¤ï¼ˆé–‹ç™ºæ®µéšç”¨ï¼‰
        # conn.execute("DROP TABLE IF EXISTS processing_results CASCADE")
        # conn.execute("DROP TABLE IF EXISTS image_metadata CASCADE")
        # conn.execute("DROP TABLE IF EXISTS experiments CASCADE")
        # conn.execute("DROP TABLE IF EXISTS datasets CASCADE")
        # conn.execute("DROP TABLE IF EXISTS models CASCADE")
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        self._create_image_metadata_table(conn)
        self._create_processing_results_table(conn)
        self._create_datasets_table(conn)
        self._create_data_samples_table(conn)
        self._create_experiments_table(conn)
        self._create_experiment_runs_table(conn)
        self._create_models_table(conn)
        
        print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
    
    def _create_image_metadata_table(self, conn):
        """ç”»åƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        conn.execute("""
            CREATE TABLE IF NOT EXISTS image_metadata (
                id INTEGER PRIMARY KEY,
                file_path VARCHAR NOT NULL,
                file_name VARCHAR NOT NULL,
                file_size BIGINT NOT NULL,
                width INTEGER NOT NULL,
                height INTEGER NOT NULL,
                format VARCHAR NOT NULL,
                mode VARCHAR NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                
                -- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”¨
                UNIQUE(file_path)
            )
        """)
    
    def _create_processing_results_table(self, conn):
        """å‡¦ç†çµæœãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        conn.execute("""
            CREATE TABLE IF NOT EXISTS processing_results (
                id INTEGER PRIMARY KEY,
                plugin_name VARCHAR NOT NULL,
                status VARCHAR NOT NULL,
                processing_time REAL NOT NULL,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                error_message TEXT,
                
                -- å…¥åŠ›ç”»åƒ
                input_image_id INTEGER,
                FOREIGN KEY (input_image_id) REFERENCES image_metadata(id),
                
                -- å‡ºåŠ›ç”»åƒ
                output_image_id INTEGER,
                FOREIGN KEY (output_image_id) REFERENCES image_metadata(id),
                
                -- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆJSONå½¢å¼ï¼‰
                parameters JSON,
                
                -- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–¢é€£
                pipeline_id VARCHAR,
                execution_id VARCHAR,
                step_index INTEGER
            )
        """)
    
    def _create_datasets_table(self, conn):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        conn.execute("""
            CREATE TABLE IF NOT EXISTS datasets (
                id INTEGER PRIMARY KEY,
                dataset_id VARCHAR UNIQUE NOT NULL,
                name VARCHAR NOT NULL,
                description TEXT,
                dataset_type VARCHAR NOT NULL,
                total_samples INTEGER DEFAULT 0,
                data_path VARCHAR NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
    
    def _create_data_samples_table(self, conn):
        """ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        conn.execute("""
            CREATE TABLE IF NOT EXISTS data_samples (
                id INTEGER PRIMARY KEY,
                sample_id VARCHAR UNIQUE NOT NULL,
                dataset_id VARCHAR NOT NULL,
                input_path VARCHAR NOT NULL,
                target_path VARCHAR,
                metadata JSON,
                labels JSON,
                preprocessing_applied JSON,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                
                FOREIGN KEY (dataset_id) REFERENCES datasets(dataset_id)
            )
        """)
    
    def _create_experiments_table(self, conn):
        """å®Ÿé¨“ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        conn.execute("""
            CREATE TABLE IF NOT EXISTS experiments (
                id INTEGER PRIMARY KEY,
                experiment_id VARCHAR UNIQUE NOT NULL,
                name VARCHAR NOT NULL,
                description TEXT,
                model_type VARCHAR NOT NULL,
                training_dataset_id VARCHAR,
                validation_dataset_id VARCHAR,
                test_dataset_id VARCHAR,
                hyperparameters JSON,
                epochs INTEGER DEFAULT 100,
                batch_size INTEGER DEFAULT 32,
                learning_rate REAL DEFAULT 0.001,
                random_seed INTEGER DEFAULT 42,
                output_dir VARCHAR NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                
                FOREIGN KEY (training_dataset_id) REFERENCES datasets(dataset_id),
                FOREIGN KEY (validation_dataset_id) REFERENCES datasets(dataset_id),
                FOREIGN KEY (test_dataset_id) REFERENCES datasets(dataset_id)
            )
        """)
    
    def _create_experiment_runs_table(self, conn):
        """å®Ÿé¨“å®Ÿè¡Œãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        conn.execute("""
            CREATE TABLE IF NOT EXISTS experiment_runs (
                id INTEGER PRIMARY KEY,
                run_id VARCHAR UNIQUE NOT NULL,
                experiment_id VARCHAR NOT NULL,
                status VARCHAR NOT NULL,
                start_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                end_time TIMESTAMP,
                duration_seconds REAL,
                training_metrics JSON,
                validation_metrics JSON,
                final_evaluation JSON,
                model_path VARCHAR,
                log_path VARCHAR,
                artifacts_path VARCHAR,
                error_message TEXT,
                error_traceback TEXT,
                
                FOREIGN KEY (experiment_id) REFERENCES experiments(experiment_id)
            )
        """)
    
    def _create_models_table(self, conn):
        """ãƒ¢ãƒ‡ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        conn.execute("""
            CREATE TABLE IF NOT EXISTS models (
                id INTEGER PRIMARY KEY,
                model_id VARCHAR UNIQUE NOT NULL,
                name VARCHAR NOT NULL,
                model_type VARCHAR NOT NULL,
                version VARCHAR NOT NULL,
                source_experiment_id VARCHAR NOT NULL,
                source_run_id VARCHAR NOT NULL,
                model_path VARCHAR NOT NULL,
                model_size_bytes BIGINT NOT NULL,
                performance_metrics JSON,
                training_dataset_id VARCHAR,
                hyperparameters JSON,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                created_by VARCHAR,
                tags JSON,
                notes TEXT,
                
                FOREIGN KEY (source_experiment_id) REFERENCES experiments(experiment_id),
                FOREIGN KEY (source_run_id) REFERENCES experiment_runs(run_id),
                FOREIGN KEY (training_dataset_id) REFERENCES datasets(dataset_id)
            )
        """)
    
    def create_indexes(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã®ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        conn = self.connect()
        
        # ã‚ˆãæ¤œç´¢ã•ã‚Œã‚‹ã‚«ãƒ©ãƒ ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_processing_results_plugin ON processing_results(plugin_name)",
            "CREATE INDEX IF NOT EXISTS idx_processing_results_timestamp ON processing_results(timestamp)",
            "CREATE INDEX IF NOT EXISTS idx_processing_results_pipeline ON processing_results(pipeline_id)",
            "CREATE INDEX IF NOT EXISTS idx_data_samples_dataset ON data_samples(dataset_id)",
            "CREATE INDEX IF NOT EXISTS idx_experiment_runs_status ON experiment_runs(status)",
            "CREATE INDEX IF NOT EXISTS idx_experiment_runs_experiment ON experiment_runs(experiment_id)",
            "CREATE INDEX IF NOT EXISTS idx_models_type ON models(model_type)",
            "CREATE INDEX IF NOT EXISTS idx_models_created ON models(created_at)",
        ]
        
        for index_sql in indexes:
            conn.execute(index_sql)
        
        print("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒä½œæˆã•ã‚Œã¾ã—ãŸ")
    
    def get_sample_data_queries(self):
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ç”¨ã®ã‚¯ã‚¨ãƒªã‚’å–å¾—"""
        return [
            # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            """
            INSERT INTO image_metadata (file_path, file_name, file_size, width, height, format, mode)
            VALUES 
                ('SampleImage/IMG_1307.jpeg', 'IMG_1307.jpeg', 1024000, 4032, 3024, 'JPEG', 'RGB'),
                ('data/processed/IMG_1307_enhanced.jpeg', 'IMG_1307_enhanced.jpeg', 1124000, 4032, 3024, 'JPEG', 'RGB')
            """,
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
            """
            INSERT INTO datasets (dataset_id, name, description, dataset_type, total_samples, data_path)
            VALUES 
                ('sample_dataset_001', 'ã‚µãƒ³ãƒ—ãƒ«ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ', 'é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç”¨ã®å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ', 'training', 1, 'SampleImage/'),
                ('test_dataset_001', 'ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ', 'æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ', 'test', 1, 'data/processed/')
            """,
            
            # ã‚µãƒ³ãƒ—ãƒ«å®Ÿé¨“
            """
            INSERT INTO experiments (experiment_id, name, description, model_type, training_dataset_id, output_dir)
            VALUES 
                ('exp_basic_001', 'åŸºæœ¬ç”»è³ªå‘ä¸Šå®Ÿé¨“', 'æ—¢å­˜ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ãŸåŸºæœ¬çš„ãªç”»è³ªå‘ä¸Šãƒ†ã‚¹ãƒˆ', 'enhancement', 'sample_dataset_001', 'data/experiments/exp_basic_001')
            """
        ]


def initialize_database(db_path: str = "data/db/advanced_image_editor.duckdb"):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹é–¢æ•°"""
    db_manager = DatabaseManager(db_path)
    
    try:
        # ã‚¹ã‚­ãƒ¼ãƒåˆæœŸåŒ–
        db_manager.initialize_schema()
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        db_manager.create_indexes()
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        conn = db_manager.connect()
        sample_queries = db_manager.get_sample_data_queries()
        
        for query in sample_queries:
            try:
                conn.execute(query)
                print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥å®Œäº†")
            except Exception as e:
                print(f"âš ï¸ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®å¯èƒ½æ€§ï¼‰: {e}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±è¡¨ç¤º
        print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±:")
        tables = conn.execute("SHOW TABLES").fetchall()
        for table in tables:
            table_name = table[0]
            count = conn.execute(f"SELECT COUNT(*) FROM {table_name}").fetchone()[0]
            print(f"  ğŸ“‹ {table_name}: {count} ãƒ¬ã‚³ãƒ¼ãƒ‰")
        
        return db_manager
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        db_manager.close()
        raise
    
    finally:
        # æ¥ç¶šã¯é–‹ã„ãŸã¾ã¾ï¼ˆä½¿ç”¨å¾Œã«ã‚¯ãƒ­ãƒ¼ã‚ºï¼‰
        pass


if __name__ == "__main__":
    # ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œæ™‚ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–
    db_manager = initialize_database()
    print("\nğŸ‰ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    db_manager.close()